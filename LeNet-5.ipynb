{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udWqLhHq35Jf"
   },
   "source": [
    "# **CIFAR10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "5nduCqoDfGxl",
    "outputId": "fa88a7bd-a34a-4ec5-b84f-356bcfa0c11d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU? True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1, Training accuracy: 0.36078, Test accuracy: 0.3535\n",
      "Epoch: 2, Training accuracy: 0.49602, Test accuracy: 0.4949\n",
      "Epoch: 3, Training accuracy: 0.51566, Test accuracy: 0.5046\n",
      "Epoch: 4, Training accuracy: 0.52948, Test accuracy: 0.5114\n",
      "Epoch: 5, Training accuracy: 0.54602, Test accuracy: 0.5238\n",
      "Epoch: 6, Training accuracy: 0.4967, Test accuracy: 0.4824\n",
      "Epoch: 7, Training accuracy: 0.60518, Test accuracy: 0.5662\n",
      "Epoch: 8, Training accuracy: 0.59802, Test accuracy: 0.554\n",
      "Epoch: 9, Training accuracy: 0.61008, Test accuracy: 0.5623\n",
      "Epoch: 10, Training accuracy: 0.66042, Test accuracy: 0.5933\n",
      "Epoch: 11, Training accuracy: 0.6765, Test accuracy: 0.5975\n",
      "Epoch: 12, Training accuracy: 0.6792, Test accuracy: 0.5907\n",
      "Epoch: 13, Training accuracy: 0.6833, Test accuracy: 0.6007\n",
      "Epoch: 14, Training accuracy: 0.69032, Test accuracy: 0.5987\n",
      "Epoch: 15, Training accuracy: 0.71752, Test accuracy: 0.6077\n",
      "Epoch: 16, Training accuracy: 0.71978, Test accuracy: 0.6059\n",
      "Epoch: 17, Training accuracy: 0.73304, Test accuracy: 0.6112\n",
      "Epoch: 18, Training accuracy: 0.716, Test accuracy: 0.5942\n",
      "Epoch: 19, Training accuracy: 0.76056, Test accuracy: 0.605\n",
      "Epoch: 20, Training accuracy: 0.75826, Test accuracy: 0.6057\n",
      "Epoch: 21, Training accuracy: 0.73294, Test accuracy: 0.5937\n",
      "Epoch: 22, Training accuracy: 0.78346, Test accuracy: 0.6057\n",
      "Epoch: 23, Training accuracy: 0.76534, Test accuracy: 0.59\n",
      "Epoch: 24, Training accuracy: 0.74114, Test accuracy: 0.5888\n",
      "Epoch: 25, Training accuracy: 0.7826, Test accuracy: 0.5981\n",
      "Epoch: 26, Training accuracy: 0.79274, Test accuracy: 0.6042\n",
      "Epoch: 27, Training accuracy: 0.78266, Test accuracy: 0.5931\n",
      "Epoch: 28, Training accuracy: 0.78656, Test accuracy: 0.5968\n",
      "Epoch: 29, Training accuracy: 0.80552, Test accuracy: 0.5936\n",
      "Epoch: 30, Training accuracy: 0.7466, Test accuracy: 0.5712\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()  # Check if GPU available \n",
    "print(\"Use GPU?\", use_cuda)\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # change the input channels from 1 to 3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        # out.size() = [batch_size, channels, size, size], -1 here means channels*size*size\n",
    "        # out.view(out.size(0), -1) is similar to out.reshape(out.size(0), -1), but more efficient\n",
    "        # Think about why we need to reshape the out?\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    " \n",
    "\n",
    "my_model = model()\n",
    "\n",
    "if use_cuda:\n",
    "  my_model = my_model.cuda()  # transfer model to GPU\n",
    "\n",
    "minibatch_size = 128\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, num_epochs, init_lr):\n",
    "    #lr = 1.0 / (epoch + 1) \n",
    "    lr = init_lr * 0.1 ** (num_epochs // 10)  \n",
    "    # epoch // 10, calculate the quotient \n",
    "    # divide lr by 10 every 10 epoches\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "init_lr = 0.1\n",
    "num_epochs = 30\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=init_lr, weight_decay = 0.0001)\n",
    "\n",
    "\n",
    "# Step 2: Define a loss function and training algorithm\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(my_model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# Step 3: load dataset\n",
    "\n",
    "CIFAR10_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=CIFAR10_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=minibatch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=CIFAR10_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "#Step 4: Train the NNs\n",
    "# One epoch is when an entire dataset is passed through the neural network only once.\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    current_lr = adjust_learning_rate(optimizer, epoch, init_lr)\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Forward pass to get the loss\n",
    "        outputs = my_model(images) \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #backpropragation\n",
    "        optimizer.step() #update the weights/parameters\n",
    "        \n",
    "    # Training accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()  \n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    training_accuracy = float(correct)/total\n",
    "\n",
    "    \n",
    "    # Test accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    test_accuracy = float(correct)/total\n",
    "        \n",
    "    print('Epoch: {}, Training accuracy: {}, Test accuracy: {}' .format(epoch+1,training_accuracy,test_accuracy))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjEtpobF4FB_"
   },
   "source": [
    "# **MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "WPhj0VulfPft",
    "outputId": "1d64ad8b-992d-4116-f1ca-8475c8ae66ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU? True\n",
      "Epoch: 1, Training accuracy: 0.8906833333333334, Test accuracy: 0.8943\n",
      "Epoch: 2, Training accuracy: 0.9568333333333333, Test accuracy: 0.9604\n",
      "Epoch: 3, Training accuracy: 0.9698333333333333, Test accuracy: 0.9707\n",
      "Epoch: 4, Training accuracy: 0.9751166666666666, Test accuracy: 0.9743\n",
      "Epoch: 5, Training accuracy: 0.979, Test accuracy: 0.9767\n",
      "Epoch: 6, Training accuracy: 0.98145, Test accuracy: 0.9795\n",
      "Epoch: 7, Training accuracy: 0.9836666666666667, Test accuracy: 0.98\n",
      "Epoch: 8, Training accuracy: 0.9857666666666667, Test accuracy: 0.9824\n",
      "Epoch: 9, Training accuracy: 0.9874, Test accuracy: 0.9834\n",
      "Epoch: 10, Training accuracy: 0.9883833333333333, Test accuracy: 0.9839\n",
      "Epoch: 11, Training accuracy: 0.98945, Test accuracy: 0.9849\n",
      "Epoch: 12, Training accuracy: 0.98915, Test accuracy: 0.9842\n",
      "Epoch: 13, Training accuracy: 0.9906833333333334, Test accuracy: 0.9853\n",
      "Epoch: 14, Training accuracy: 0.9910666666666667, Test accuracy: 0.9844\n",
      "Epoch: 15, Training accuracy: 0.9905333333333334, Test accuracy: 0.984\n",
      "Epoch: 16, Training accuracy: 0.9913333333333333, Test accuracy: 0.9847\n",
      "Epoch: 17, Training accuracy: 0.9919166666666667, Test accuracy: 0.9845\n",
      "Epoch: 18, Training accuracy: 0.9921166666666666, Test accuracy: 0.9848\n",
      "Epoch: 19, Training accuracy: 0.9920666666666667, Test accuracy: 0.9842\n",
      "Epoch: 20, Training accuracy: 0.9927666666666667, Test accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use GPU?', use_cuda)\n",
    "\n",
    "# Define a LeNet-5\n",
    "# Note that we need to reshape MNIST imgaes 28*28 to 32*32\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "my_model = model()\n",
    "\n",
    "if use_cuda:\n",
    "  my_model = my_model.cuda()  # transfer model to GPU\n",
    "\n",
    "minibatch_size = 128\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, num_epochs, init_lr):\n",
    "    #lr = 1.0 / (epoch + 1) \n",
    "    lr = init_lr * 0.1 ** (num_epochs // 10)  \n",
    "    # epoch // 10, calculate the quotient \n",
    "    # divide lr by 10 every 10 epoches\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "init_lr = 0.1\n",
    "num_epochs = 20\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=init_lr, weight_decay = 0.0001)\n",
    "\n",
    "\n",
    "# Step 3: load dataset\n",
    "\n",
    "MNIST_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)),\n",
    "                                                  torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train= True, download=True, transform=MNIST_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=minibatch_size)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train= False, download=True, transform=MNIST_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset)) \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Forward pass to get the loss\n",
    "        outputs = my_model(images) \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #backpropragation\n",
    "        optimizer.step() #update the weights/parameters\n",
    "        \n",
    "    # Training accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()  \n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    training_accuracy = float(correct)/total\n",
    "\n",
    "    \n",
    "    # Test accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "        outputs = my_model(images)\n",
    "        p_max, predicted = torch.max(outputs, 1) \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    test_accuracy = float(correct)/total\n",
    "        \n",
    "    print('Epoch: {}, Training accuracy: {}, Test accuracy: {}' .format(epoch+1,training_accuracy,test_accuracy))  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Week4_coding .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
